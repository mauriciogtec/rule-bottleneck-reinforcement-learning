{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from langchain_together import TogetherEmbeddings\n",
    "from llm_apis import get_llm_api\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = TogetherEmbeddings(model=\"togethercomputer/m2-bert-80M-8k-retrieval\")\n",
    "llm = get_llm_api(\"gpt-4o-mini-huit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>agent</th>\n",
       "      <th>episode</th>\n",
       "      <th>recommended_action</th>\n",
       "      <th>explanation</th>\n",
       "      <th>rules</th>\n",
       "      <th>state_numeric</th>\n",
       "      <th>rules_numeric</th>\n",
       "      <th>sel_rule_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- Location [FIPS code]: 06025\\n- Remaining war...</td>\n",
       "      <td>base_agent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In the current state, I observed a high heat i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7964519262313843, 1.0, 1.0, 1.0763599872589...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>- Location [FIPS code]: 06025\\n- Remaining war...</td>\n",
       "      <td>tbrl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In the current state, I observed a heat index ...</td>\n",
       "      <td>[\"1. High heat index indicates immediate risk....</td>\n",
       "      <td>[0.7964519262313843, 1.0, 1.0, 1.0763599872589...</td>\n",
       "      <td>[[0.07000600546598434, 0.038187749683856964, 0...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- Location [FIPS code]: 06025\\n- Remaining war...</td>\n",
       "      <td>rbrl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In the current state, I observed a high heat i...</td>\n",
       "      <td>[\"- {\\\"background\\\": \\\"High heat index today. ...</td>\n",
       "      <td>[0.7964519262313843, 1.0, 1.0, 1.0763599872589...</td>\n",
       "      <td>[[0.12648765742778778, -0.01651541143655777, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Location [FIPS code]: 48469\\n- Remaining war...</td>\n",
       "      <td>base_agent</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In the current state, I observed a high heat i...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.6988795399665833, 1.0, 0.0, 1.0009399652481...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Location [FIPS code]: 48469\\n- Remaining war...</td>\n",
       "      <td>tbrl</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>In the current state, I observed a heat index ...</td>\n",
       "      <td>[\"1. High heat index indicates immediate risk....</td>\n",
       "      <td>[0.6988795399665833, 1.0, 0.0, 1.0009399652481...</td>\n",
       "      <td>[[-0.0538608580827713, 0.13751941919326782, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>- Location [FIPS code]: 04027\\n- Remaining war...</td>\n",
       "      <td>tbrl</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>In the current state, I observed a remaining w...</td>\n",
       "      <td>[\"1) No budget remaining for warnings.  \\n2) H...</td>\n",
       "      <td>[0.6911764740943909, 1.0, 0.0, 1.0522400140762...</td>\n",
       "      <td>[[0.04970642924308777, 0.012701241299510002, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>- Location [FIPS code]: 04027\\n- Remaining war...</td>\n",
       "      <td>rbrl</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>In the current state, I observed a high heat i...</td>\n",
       "      <td>[\"- {\\\"background\\\": \\\"Budget is exhausted tod...</td>\n",
       "      <td>[0.6911764740943909, 1.0, 0.0, 1.0522400140762...</td>\n",
       "      <td>[[0.006734743248671293, 0.15140937268733978, -...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>- Location [FIPS code]: 04027\\n- Remaining war...</td>\n",
       "      <td>base_agent</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>In the current state, I observed that the rema...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.7040149569511414, 1.0, 0.0, 1.0542199611663...</td>\n",
       "      <td>[]</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>- Location [FIPS code]: 04027\\n- Remaining war...</td>\n",
       "      <td>tbrl</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>In the current state, I observed a remaining w...</td>\n",
       "      <td>[\"1. Current budget for warnings is zero.  \\n2...</td>\n",
       "      <td>[0.7040149569511414, 1.0, 0.0, 1.0542199611663...</td>\n",
       "      <td>[[0.10169322043657303, 0.054078035056591034, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>- Location [FIPS code]: 04027\\n- Remaining war...</td>\n",
       "      <td>rbrl</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>In the current state, I observed that there is...</td>\n",
       "      <td>[\"- {\\\"background\\\": \\\"No budget for warnings ...</td>\n",
       "      <td>[0.7040149569511414, 1.0, 0.0, 1.0542199611663...</td>\n",
       "      <td>[[0.07607410103082657, 0.05248866230249405, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 state       agent  episode  \\\n",
       "0    - Location [FIPS code]: 06025\\n- Remaining war...  base_agent        0   \n",
       "1    - Location [FIPS code]: 06025\\n- Remaining war...        tbrl        0   \n",
       "2    - Location [FIPS code]: 06025\\n- Remaining war...        rbrl        0   \n",
       "3    - Location [FIPS code]: 48469\\n- Remaining war...  base_agent        0   \n",
       "4    - Location [FIPS code]: 48469\\n- Remaining war...        tbrl        0   \n",
       "..                                                 ...         ...      ...   \n",
       "475  - Location [FIPS code]: 04027\\n- Remaining war...        tbrl        9   \n",
       "476  - Location [FIPS code]: 04027\\n- Remaining war...        rbrl        9   \n",
       "477  - Location [FIPS code]: 04027\\n- Remaining war...  base_agent        9   \n",
       "478  - Location [FIPS code]: 04027\\n- Remaining war...        tbrl        9   \n",
       "479  - Location [FIPS code]: 04027\\n- Remaining war...        rbrl        9   \n",
       "\n",
       "     recommended_action                                        explanation  \\\n",
       "0                     1  In the current state, I observed a high heat i...   \n",
       "1                     1  In the current state, I observed a heat index ...   \n",
       "2                     1  In the current state, I observed a high heat i...   \n",
       "3                     1  In the current state, I observed a high heat i...   \n",
       "4                     1  In the current state, I observed a heat index ...   \n",
       "..                  ...                                                ...   \n",
       "475                   0  In the current state, I observed a remaining w...   \n",
       "476                   0  In the current state, I observed a high heat i...   \n",
       "477                   0  In the current state, I observed that the rema...   \n",
       "478                   0  In the current state, I observed a remaining w...   \n",
       "479                   0  In the current state, I observed that there is...   \n",
       "\n",
       "                                                 rules  \\\n",
       "0                                                   []   \n",
       "1    [\"1. High heat index indicates immediate risk....   \n",
       "2    [\"- {\\\"background\\\": \\\"High heat index today. ...   \n",
       "3                                                   []   \n",
       "4    [\"1. High heat index indicates immediate risk....   \n",
       "..                                                 ...   \n",
       "475  [\"1) No budget remaining for warnings.  \\n2) H...   \n",
       "476  [\"- {\\\"background\\\": \\\"Budget is exhausted tod...   \n",
       "477                                                 []   \n",
       "478  [\"1. Current budget for warnings is zero.  \\n2...   \n",
       "479  [\"- {\\\"background\\\": \\\"No budget for warnings ...   \n",
       "\n",
       "                                         state_numeric  \\\n",
       "0    [0.7964519262313843, 1.0, 1.0, 1.0763599872589...   \n",
       "1    [0.7964519262313843, 1.0, 1.0, 1.0763599872589...   \n",
       "2    [0.7964519262313843, 1.0, 1.0, 1.0763599872589...   \n",
       "3    [0.6988795399665833, 1.0, 0.0, 1.0009399652481...   \n",
       "4    [0.6988795399665833, 1.0, 0.0, 1.0009399652481...   \n",
       "..                                                 ...   \n",
       "475  [0.6911764740943909, 1.0, 0.0, 1.0522400140762...   \n",
       "476  [0.6911764740943909, 1.0, 0.0, 1.0522400140762...   \n",
       "477  [0.7040149569511414, 1.0, 0.0, 1.0542199611663...   \n",
       "478  [0.7040149569511414, 1.0, 0.0, 1.0542199611663...   \n",
       "479  [0.7040149569511414, 1.0, 0.0, 1.0542199611663...   \n",
       "\n",
       "                                         rules_numeric  sel_rule_idx  \n",
       "0                                                   []            -1  \n",
       "1    [[0.07000600546598434, 0.038187749683856964, 0...             4  \n",
       "2    [[0.12648765742778778, -0.01651541143655777, 0...             1  \n",
       "3                                                   []            -1  \n",
       "4    [[-0.0538608580827713, 0.13751941919326782, -0...             0  \n",
       "..                                                 ...           ...  \n",
       "475  [[0.04970642924308777, 0.012701241299510002, -...             0  \n",
       "476  [[0.006734743248671293, 0.15140937268733978, -...             2  \n",
       "477                                                 []            -1  \n",
       "478  [[0.10169322043657303, 0.054078035056591034, 0...             1  \n",
       "479  [[0.07607410103082657, 0.05248866230249405, -0...             0  \n",
       "\n",
       "[480 rows x 9 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"notebooks/wandb_export_2025-03-31T17_23_57.012-04_00.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the current state, I observed a heat index of 107 F and a forecast of high temperatures for the next several days. I reasoned that issuing a warning now would help protect public health, as the heat index is significantly above average. I concluded that issuing a warning is the optimal action.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.explanation.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess all explanations. Ask chat-gpt to remove the action\n",
    "prompt = \"\"\"\n",
    "    You will be given an explanation of the action taken by an RL agent. Your role is to\n",
    "    remove the action from the explanation. \n",
    "    \n",
    "    Examples:\n",
    "    - In the current state, I observed a heat index of 107. I concluded that issuing a warning is the optimal action. -> In the current state, I observed a heat index of 107. I concluded that XXX. (mask action with XXX)\n",
    "    - In the current state, I observed a heat index of 107 F and a forecast of high temperatures -> In the current state, I observed a heat index of 107 F and a forecast of high temperatures (no change because no action is mentioned).\n",
    "\n",
    "    You don't need to mask a hypothetical language. For example,\n",
    "    - I used a rule stating that *if* heat is > 100F, then I should issue a warning. -> I used a rule stating that if heat is > 100F, then I should issue a warning. (no change because no action is mentioned).\n",
    "\n",
    "    However, do mask any conclusive language. For example,\n",
    "    - I observed a heat index of 107, and reasoned that I should issue a warning. -> I observed a heat index of 107, and reasoned that I should XXX. (mask action with XXX)\n",
    "\n",
    "    Sentence to mask: {}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 59/153 [01:57<02:54,  1.85s/it]/net/rcstorenfs02/ifs/rc_labs/dominici_lab/lab/projects/mauricio-rbrl/llm_apis.py:304: UserWarning: Attempt 1 failed: 504 Server Error: Gateway Timeout for url: https://go.apis.huit.harvard.edu/ais-openai-direct/v1/chat/completions\n",
      "  warnings.warn(f\"Attempt {attempts} failed: {e}\")\n",
      "100%|██████████| 153/153 [08:17<00:00,  3.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "explanations = df.explanation.values\n",
    "actions = df.recommended_action.values\n",
    "agents = df.agent.values\n",
    "\n",
    "# messages = [[{\"role\": \"user\", \"content\": prompt.format(explanation)}] for explanation in explanations]\n",
    "\n",
    "processed_explanations = []\n",
    "for expl, a in tqdm(zip(explanations, actions), total=len(messages)):\n",
    "    # if \"I concluded\" in expl:\n",
    "    #     new_expl = expl.split(\"I concluded\")[0]\n",
    "    #     processed_explanations.append(new_expl)\n",
    "    message = [{\"role\": \"user\", \"content\": prompt.format(expl)}]\n",
    "    response = llm.invoke(message).content\n",
    "    processed_explanations.append(response)\n",
    "\n",
    "print(len(explanations))\n",
    "print(len(processed_explanations))\n",
    "\n",
    "embeddings = embedder.embed_documents(processed_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "0. [base_agent] [episode 0; step 0] In the current state, I observed a high heat index of 107 F and a forecast of continued high temperatures. Then, I reasoned that immediate warnings can save lives, and the budget allows for more warnings without causing fatigue. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. [tbrl] [episode 0; step 0] In the current state, I observed a heat index of 107 F and a forecast of high temperatures for the next several days. I reasoned that XXX would help protect public health, as the heat index is significantly above average. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2. [rbrl] [episode 0; step 0] In the current state, I observed a high heat index of 107 F, no recent warnings, and a remaining budget of 10 warnings. Then, I reasoned that XXX could effectively protect public health, especially with future heatwaves forecasted. I applied the rule stating that if there have been no warnings in the last 3 days and the remaining warnings are positive, then a warning should be issued. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3. [base_agent] [episode 0; step 1] In the current state, I observed a high heat index of 101 F and that it is a weekend. I reasoned that XXX could prevent health issues during this critical time, especially with upcoming heat forecasts indicating more high temperatures. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4. [tbrl] [episode 0; step 1] In the current state, I observed a heat index of 101 F and a weekend day. There is a remaining warning budget of 9 and a forecast of high temperatures for the next week. I concluded that XXX to protect public health."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5. [rbrl] [episode 0; step 1] In the current state, I observed a high heat index of 101 F and a weekend day, which increases exposure risk. Then, I reasoned that XXX could help protect public health, especially since the budget allows for it and there is a forecast of future heatwaves. I applied the rule stating that if warnings in the last 3 days equal 1 and the remaining budget is greater than 0, I should XXX. Applying this rule to the current state, I concluded that XXX is the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6. [base_agent] [episode 0; step 2] In the current state, I observed a high heat index of 97 F and a warning streak of 2. Then, I reasoned that warning fatigue may reduce effectiveness and future heatwaves are predicted. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "7. [tbrl] [episode 0; step 2] In the current state, I observed a heat index of 97 F and a warning streak of 2. The forecast shows high temperatures for the next week, but warning fatigue is a concern. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "8. [rbrl] [episode 0; step 2] In the current state, I observed a high heat index of 97 F and a warning streak of 2 in the last 3 days. Then, I reasoned that issuing another warning could lead to warning fatigue, reducing its effectiveness. I applied the rule stating that if warnings in the last 3 days are 2 and remaining warnings are greater than 1, I should XXX. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "9. [base_agent] [episode 0; step 3] In the current state, I observed a high heat index of 91 F and increasing future heat indices, peaking at 101 F. Then, I reasoned that immediate action could prevent health risks, and the budget allows for more warnings. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "10. [tbrl] [episode 0; step 3] In the current state, I observed a heat index of 91 F and a forecast of increasing temperatures, peaking at 101 F in the coming days. I reasoned that XXX would help mitigate health risks during the upcoming heatwave, especially since the warning budget allows for it. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11. [rbrl] [episode 0; step 3] In the current state, I observed a current heat index of 91 F, a warning budget of 8, and no recent warning streak. Then, I reasoned that immediate warnings can save lives, especially with worsening heat forecasts ahead. I applied the rule stating that if there is no warning streak and remaining warnings are available, I should XXX. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "12. [base_agent] [episode 0; step 4] In the current state, I observed a high heat index of 98 F and a warning streak of 1. Then, I reasoned that immediate warnings can reduce health risks, but warning fatigue is a concern. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "13. [tbrl] [episode 0; step 4] In the current state, I observed a heat index of 98 F and a warning streak of 1. The forecast predicts high temperatures for the next several days, with values reaching up to 103 F. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "14. [rbrl] [episode 0; step 4] In the current state, I observed a high heat index of 98 F and a warning streak of 1. Then, I reasoned that immediate warnings are necessary due to the high temperatures forecasted for the next few days. I applied the rule stating that if warnings in the last 3 days are less than 2 and remaining warnings are available, then XXX. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "15. [base_agent] [episode 0; step 5] In the current state, I observed a high heat index of 99 F and a warning streak of 2. Then, I reasoned that immediate warnings can prevent health issues, but warning fatigue may reduce effectiveness. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "16. [tbrl] [episode 0; step 5] In the current state, I observed a heat index of 99 F and a warning streak of 2. The forecast predicts high temperatures for the next several days, with values reaching 100 F. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "17. [rbrl] [episode 0; step 5] In the current state, I observed that there have been 2 warnings in the last 3 days and the remaining warning budget is 6. Then, I reasoned that issuing too many warnings in a row could lead to warning fatigue, reducing their effectiveness in the future. I applied the rule stating that if warnings in the last 3 days are 2 or more and remaining warnings are positive, then do not issue a warning. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "18. [base_agent] [episode 0; step 6] In the current state, I observed a high heat index of 98 F and a warning streak of three warnings in the last three days. Then, I reasoned that warning fatigue could reduce the effectiveness of future warnings, especially with heatwaves forecasted for the next week. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "19. [tbrl] [episode 0; step 6] In the current state, I observed a heat index of 98 F and a warning streak of 3. I reasoned that XXX could help mitigate health risks, especially with high temperatures forecasted for the next few days. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "20. [rbrl] [episode 0; step 6] In the current state, I observed a high heat index of 98 F and a warning streak of 3 in the last 3 days. Then, I reasoned that immediate warnings are crucial due to the high heat and upcoming heatwaves, but warning fatigue could reduce effectiveness. I applied the rule stating that if the current heat index is above 95 F and warnings in the last 3 days are less than 3, I should XXX. Applying this rule to the current state, I concluded"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "21. [base_agent] [episode 0; step 7] In the current state, I observed a high heat index of 98 F and a forecast of even hotter temperatures in the coming days. Then, I reasoned that XXX could help prevent health issues, despite the risk of warning fatigue from recent warnings. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "22. [tbrl] [episode 0; step 7] In the current state, I observed a heat index of 98 F and a warning streak of 4. The forecast predicts high temperatures for the next several days, with a maximum of 105 F. I concluded that XXX is the optimal action to protect public health."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "23. [rbrl] [episode 0; step 7] In the current state, I observed a high heat index of 98 F and a forecast of 99 F for the next day. Then, I reasoned that XXX could help protect public health effectively, especially with future heatwaves expected. I applied the rule stating that a warning should be issued if the next day's forecast exceeds 98 F and there are remaining warnings available. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "24. [base_agent] [episode 0; step 8] In the current state, I observed a high heat index of 99 F and a warning streak of 5. Then, I reasoned that immediate action may prevent health issues, despite the risk of warning fatigue. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "25. [tbrl] [episode 0; step 8] In the current state, I observed a heat index of 99 F and a warning streak of 5. The remaining budget allows for 3 warnings, and the forecast shows high temperatures for the next several days. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "26. [rbrl] [episode 0; step 8] In the current state, I observed a high heat index of 99 F on a weekend, with a remaining warning budget of 3. Then, I reasoned that XXX today could help protect public health, especially since outdoor activities may increase during weekends. I applied the rule stating that if today is a weekend and the current heat index is above 98 F, I should XXX. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "27. [base_agent] [episode 0; step 9] In the current state, I observed a high heat index of 100 F and a warning streak of 6. Then, I reasoned that XXX could help protect public health, despite the risk of warning fatigue. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "28. [tbrl] [episode 0; step 9] In the current state, I observed a heat index of 100 F and a warning streak of 6. The remaining budget allows for 2 warnings, and the forecast shows high temperatures for the next week. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "29. [rbrl] [episode 0; step 9] In the current state, I observed a high heat index of 100 F and a warning streak of 6 in the last 14 days. Then, I reasoned that too many warnings can lead to warning fatigue, reducing their effectiveness. I applied the rule stating that I should not issue a warning if warnings in the last 7 days are greater than or equal to 5 and the remaining budget is positive. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "30. [base_agent] [episode 0; step 10] In the current state, I observed a high heat index of 99 F and a warning streak of 7. Then, I reasoned that warning fatigue could reduce the effectiveness of future warnings, and I have only one warning left in the budget. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "31. [tbrl] [episode 0; step 10] In the current state, I observed a heat index of 99 F and a warning streak of 7. The remaining budget allows for one warning, and the forecast shows high temperatures for the next several days. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "32. [rbrl] [episode 0; step 10] In the current state, I observed a high heat index of 99 F and a warning streak of 7 in the last 14 days. Then, I reasoned that immediate health protection is crucial despite the risk of warning fatigue. I applied the rule stating that if warnings in the last 3 days are 3 or more and the current heat index exceeds 95 F, a warning should be issued. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "33. [base_agent] [episode 0; step 11] In the current state, I observed a remaining warning budget of zero and a high heat index of 99 F. Then, I reasoned that without a budget, issuing a warning is not possible, and the recent warning streak may lead to fatigue. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "34. [tbrl] [episode 0; step 11] In the current state, I observed a remaining warning budget of 0 and a warning streak of 8. Then, I reasoned that XXX is not possible due to the budget constraint, and the high number of recent warnings may lead to warning fatigue. I concluded that 0 is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "35. [rbrl] [episode 0; step 11] In the current state, I observed a high heat index of 99 F, a warning budget of 0, and a warning streak of 8 in the last 14 days. Then, I reasoned that issuing too many warnings can lead to warning fatigue, reducing their effectiveness. I applied the rule stating that if the heat index is high and warnings in the last 7 days are excessive, then do not issue a warning. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "36. [base_agent] [episode 0; step 12] In the current state, I observed that there is no remaining warning budget available. Then, I reasoned that XXX is not possible, and warning fatigue could occur if warnings are issued consecutively. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "37. [tbrl] [episode 0; step 12] In the current state, I observed a remaining warning budget of 0 and a current heat index of 96 F. I reasoned that without budget, issuing a warning is not possible. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "38. [rbrl] [episode 0; step 12] In the current state, I observed that the remaining warning budget is zero. Then, I reasoned that XXX is not possible today due to the budget constraint. I applied the rule stating that if warnings cannot be issued, then the optimal action is to do nothing. Applying this rule to the current state, I concluded that 0 is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "39. [base_agent] [episode 0; step 13] In the current state, I observed a remaining warning budget of zero and a high heat index of 101 F. Then, I reasoned that no warnings can be issued now, and future heatwave forecasts are concerning. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "40. [tbrl] [episode 0; step 13] In the current state, I observed a remaining warning budget of 0 and a current heat index of 101 F. Then, I reasoned that without a budget, issuing a warning is not possible, and the current heat index is already high. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "41. [rbrl] [episode 0; step 13] In the current state, I observed that the remaining warning budget is 0 and there have been 5 warnings in the last 7 days. Then, I reasoned that issuing more warnings could lead to warning fatigue, reducing their effectiveness. I applied the rule stating that if warnings in the last 7 days are 5 or more, then delay issuing a warning. Applying this rule to the current state, I concluded that not issuing a warning is the optimal XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "42. [base_agent] [episode 0; step 14] In the current state, I observed a high heat index of 100 F and no remaining budget for warnings. Then, I reasoned that XXX without budget, and warning fatigue could worsen future responses. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "43. [tbrl] [episode 0; step 14] In the current state, I observed a remaining warning budget of 0 and a current heat index of 100 F. Then, I reasoned that without budget, XXX is not possible. I concluded that 0 is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "44. [rbrl] [episode 0; step 14] In the current state, I observed that there is no remaining warning budget and that warnings in the last 7 days exceed 3. Then, I reasoned that issuing another warning could lead to warning fatigue and reduce effectiveness. I applied the rule stating that if warnings in the last 7 days exceed 3, then do not issue a warning. Applying this rule to the current state, I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "45. [base_agent] [episode 0; step 15] In the current state, I observed that there is no remaining budget for issuing warnings. Then, I reasoned that without budget, I cannot issue a warning despite the high heat index and future forecasts. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "46. [tbrl] [episode 0; step 15] In the current state, I observed a remaining warning budget of 0 and a heat index of 98 F. I reasoned that without budget, issuing a warning is not possible. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "47. [rbrl] [episode 0; step 15] In the current state, I observed a remaining warning budget of 0 and 9 warnings issued in the last 14 days. Then, I reasoned that issuing more warnings could lead to public fatigue and is not possible due to the budget constraint. I applied the rule stating that if warnings in the last 14 days are greater than 8, do not issue a warning. Applying this rule to the current state, I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "48. [base_agent] [episode 1; step 16] In the current state, I observed a high heat index of 94 F and a forecast of rising temperatures. Then, I reasoned that XXX can help reduce health impacts and that the budget allows for proactive measures. I concluded that XXX is the optimal action."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "49. [tbrl] [episode 1; step 16] In the current state, I observed a heat index of 94 F and a weekend day. There have been no warnings issued recently, and the remaining budget allows for 10 warnings. I concluded that XXX."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def printmd(text):\n",
    "    from IPython.display import Markdown, display\n",
    "    display(Markdown(text))\n",
    "\n",
    "for i in range(50):\n",
    "    printmd(f\"{i}. [{df.agent.iloc[i]}] [episode {df.episode.iloc[i]}; step {i // 3}] {processed_explanations[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = df.explanation.values\n",
    "actions = df.recommended_action.values\n",
    "agent = df.agent.values\n",
    "\n",
    "# messages = [[{\"role\": \"user\", \"content\": prompt.format(explanation)}] for explanation in explanations]\n",
    "\n",
    "processed_explanations = []\n",
    "for expl, a in tqdm(zip(explanations, actions), total=len(messages)):\n",
    "    # if \"I concluded\" in expl:\n",
    "    #     new_expl = expl.split(\"I concluded\")[0]\n",
    "    #     processed_explanations.append(new_expl)\n",
    "    message = [{\"role\": \"user\", \"content\": prompt.format(expl)}]\n",
    "    response = llm.invoke(message).content\n",
    "    processed_explanations.append(response)\n",
    "\n",
    "print(len(explanations))\n",
    "print(len(processed_explanations))\n",
    "\n",
    "embeddings = embedder.embed_documents(processed_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: base_agent, Accuracy: 0.8235, F1 Score: 0.8043\n",
      "Agent: tbrl, Accuracy: 0.9216, F1 Score: 0.9089\n",
      "Agent: rbrl, Accuracy: 0.9804, F1 Score: 0.9799\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# preprocess all explanations. Ask chat-gpt to remove the action\n",
    "prompt2 = \"\"\"\n",
    "    Below is an explanation of the action taken by an RL agent. Your role is to guess which action was taken. \n",
    "    There are only two actions available, 0=no heat warning alert, 1=heat warning alert.\n",
    "    Your response should be a single number, either 0 or 1.\n",
    "\n",
    "    Masked explanation: {}\n",
    "\"\"\"\n",
    "\n",
    "predictions = []\n",
    "for i in tqdm(range(len(processed_explanations))):\n",
    "    # if \"I concluded\" in expl:\n",
    "    #     new_expl = expl.split(\"I concluded\")[0]\n",
    "    #     processed_explanations.append(new_expl)\n",
    "    message = [{\"role\": \"user\", \"content\": prompt2.format(processed_explanations[i])}]\n",
    "    response = llm.invoke(message).content\n",
    "    predictions.append(int(response))\n",
    "\n",
    "predictions = np.array(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from sklearn.utils import resample\n",
    "\n",
    "for agent in df.agent.unique():\n",
    "    y_true = df[df.agent == agent].recommended_action.values\n",
    "    y_pred = predictions[df.agent == agent]\n",
    "    \n",
    "    # Compute accuracy and its confidence interval using bootstrapping\n",
    "    accuracy_scores = []\n",
    "    for _ in range(1000):  # Number of bootstrap samples\n",
    "        y_true_sample, y_pred_sample = resample(y_true, y_pred)\n",
    "        accuracy_scores.append(np.mean(y_true_sample == y_pred_sample))\n",
    "    accuracy = np.mean(accuracy_scores)\n",
    "    ci_lower_acc = np.percentile(accuracy_scores, 2.5)\n",
    "    ci_upper_acc = np.percentile(accuracy_scores, 97.5)\n",
    "\n",
    "    # Compute F1 score and its confidence interval using bootstrapping\n",
    "    f1_scores = []\n",
    "    for _ in range(1000):  # Number of bootstrap samples\n",
    "        y_true_sample, y_pred_sample = resample(y_true, y_pred)\n",
    "        f1_scores.append(f1_score(y_true_sample, y_pred_sample, average=\"macro\"))\n",
    "    f1 = np.mean(f1_scores)\n",
    "    ci_lower_f1 = np.percentile(f1_scores, 2.5)\n",
    "    ci_upper_f1 = np.percentile(f1_scores, 97.5)\n",
    "    \n",
    "    print(f\"Agent: {agent}, Accuracy: {accuracy:.4f} (95% CI: [{ci_lower_acc:.4f}, {ci_upper_acc:.4f}]), \"\n",
    "          f\"F1 Score: {f1:.4f} (95% CI: [{ci_lower_f1:.4f}, {ci_upper_f1:.4f}])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "embeddings = torch.tensor(embeddings).to(dev)\n",
    "actions = torch.tensor(df.recommended_action.values).to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training for agent base_agent ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 22/500 [00:00<00:02, 219.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6569, Accuracy: 0.6364, F1 Score: 0.7778\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 45/500 [00:00<00:02, 220.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6565, Accuracy: 0.6364, F1 Score: 0.7778\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 68/500 [00:00<00:01, 221.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6342, Accuracy: 0.6364, F1 Score: 0.7778\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 114/500 [00:00<00:01, 222.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5941, Accuracy: 0.7273, F1 Score: 0.8235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160/500 [00:00<00:01, 223.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5428, Accuracy: 0.7273, F1 Score: 0.8235\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [00:00<00:01, 222.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4896, Accuracy: 0.8182, F1 Score: 0.8571\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 252/500 [00:01<00:01, 222.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4477, Accuracy: 0.9091, F1 Score: 0.9231\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/500 [00:01<00:00, 223.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4036, Accuracy: 0.8182, F1 Score: 0.8333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 344/500 [00:01<00:00, 224.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3847, Accuracy: 0.8182, F1 Score: 0.8333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 390/500 [00:01<00:00, 224.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3571, Accuracy: 0.8182, F1 Score: 0.8333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 436/500 [00:01<00:00, 224.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3407, Accuracy: 0.8182, F1 Score: 0.8333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 222.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training for agent tbrl ======8182, F1 Score: 0.8333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 45/500 [00:00<00:02, 222.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6723, Accuracy: 0.8182, F1 Score: 0.9000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 68/500 [00:00<00:01, 222.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6163, Accuracy: 0.8182, F1 Score: 0.9000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 114/500 [00:00<00:01, 222.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5271, Accuracy: 0.8182, F1 Score: 0.9000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160/500 [00:00<00:01, 224.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4360, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [00:00<00:01, 221.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3763, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 252/500 [00:01<00:01, 220.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3160, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/500 [00:01<00:00, 220.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2695, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 344/500 [00:01<00:00, 220.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2310, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 390/500 [00:01<00:00, 220.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2341, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 436/500 [00:01<00:00, 220.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2115, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 481/500 [00:02<00:00, 219.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2002, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 220.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Training for agent rbrl ======0000, F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 22/500 [00:00<00:02, 219.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6415, Accuracy: 0.6364, F1 Score: 0.7778\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 45/500 [00:00<00:02, 221.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6366, Accuracy: 0.6364, F1 Score: 0.7778\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 68/500 [00:00<00:01, 222.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5449, Accuracy: 0.9091, F1 Score: 0.9333\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 114/500 [00:00<00:01, 221.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4011, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 160/500 [00:00<00:01, 221.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2971, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [00:00<00:01, 222.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2334, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 252/500 [00:01<00:01, 222.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1915, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 298/500 [00:01<00:00, 221.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1790, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 344/500 [00:01<00:00, 220.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1593, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 390/500 [00:01<00:00, 221.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1424, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 436/500 [00:01<00:00, 222.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1340, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 482/500 [00:02<00:00, 223.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1201, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 221.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1192, Accuracy: 1.0000, F1 Score: 1.0000\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a model per agent\n",
    "\n",
    "for agent in df.agent.unique():\n",
    "    print(f\"====== Training for agent {agent} ======\")\n",
    "\n",
    "    emb_agent = embeddings[agent == df.agent.values]\n",
    "    actions_agent = actions[agent == df.agent.values]\n",
    "\n",
    "    train_dataset = TensorDataset(emb_agent, actions_agent)\n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    test_size = len(train_dataset) - train_size\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(train_dataset, [train_size, test_size])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize the model\n",
    "    action_classifier = nn.Sequential(\n",
    "        nn.Linear(768, 16),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(16, 16),\n",
    "        nn.SiLU(),\n",
    "        nn.Dropout(0.5),\n",
    "        nn.Linear(16, 1),\n",
    "    ).to(dev)\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        action_classifier.parameters(),\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-4,\n",
    "    )\n",
    "    # Training loop\n",
    "    num_epochs = 500\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        action_classifier.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(dev), labels.to(dev)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = action_classifier(inputs).squeeze(-1)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader):.4f}\", end=\"\\r\")\n",
    "\n",
    "        # Validation loop with accuracy and F1 score\n",
    "        action_classifier.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_dataloader:\n",
    "                inputs, labels = inputs.to(dev), labels.to(dev)\n",
    "\n",
    "                outputs = action_classifier(inputs).squeeze(-1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = torch.round(torch.sigmoid(outputs))\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = correct / total\n",
    "\n",
    "        # f1 score\n",
    "        y_true = labels.cpu().numpy()\n",
    "        y_pred = predicted.cpu().numpy()\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        print(f\"Validation Loss: {val_loss / len(test_dataloader):.4f}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbrl = df[df.agent == \"rbrl\"].copy()\n",
    "for r, i in zip(df_rbrl.rules, df_rbrl.rule_sel_index):\n",
    "    r_parsed = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
